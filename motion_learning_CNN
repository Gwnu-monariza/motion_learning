import tensorflow as tf
import numpy as np
batch_size = 128
epochs = 8
num_classes = 10

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()  #input data 변경
x_train = x_train / 255.0
x_test = x_test / 255.0

new_x_train=[]
for ir in range(x_train.shape[0])
    new_x_train.append(tf.image.resize(x_train, 
                    [84,84], 
                    method=ResizeMethod.BILINEAR, 
                    preserve_aspect_ratio=False,
                    antialias=False, 
                    name=None))
#5000,84,84,3

new_y_train=[]
for ir in range(x_train.shape[0])
    new_y_train.append(tf.image.resize(y_train, 
                    [84,84], 
                    method=ResizeMethod.BILINEAR, 
                    preserve_aspect_ratio=False,
                    antialias=False, 
                    name=None))
#5000,84,84,3


    ---------------------------------------------------------------------------------------------
# 모델 입력 데이터 훈련, 테스트용 준비
y_train = tf.keras.utils.to_categorical(y_train, num_classes) # 벡터>이진 클래스 행렬 변환
y_test = tf.keras.utils.to_categorical(y_test, num_classes)
#모델 구성 함수
def build_model(in_shape):
    #입력데이터
    input_data = tf.keras.layers.Input(shape = (in_shape[1], in_shape[2], in_shape[3])) #n차원 벡터 일관처리, 지정없으면 None 
    
    #컨볼루션 레이어 1층
    conv2d_1 = tf.keras.layers.Conv2D(input_shape = (in_shape[1], in_shape[2], in_shape[3]),
                               padding='same', 
                               kernel_initializer='glorot_normal', 
                               bias_initializer='zeros', 
                               filters=32, 
                               kernel_size=(3,3),
                               activation='relu')(input_data)
    #드롭아웃
    dropout_1 = tf.keras.layers.Dropout(rate=0.4)(conv2d_1) # (드롭단위 비율, 호출인수)
    maxpool2d_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(dropout_1) #dropout_1 size(2, 2)로 축소

    #컨볼루션 레이어 2층
    conv2d_2 = tf.keras.layers.Conv2D(padding='same', 
                               kernel_initializer='glorot_normal', 
                               bias_initializer='zeros', 
                               filters=64, 
                               kernel_size=(3,3),
                               activation='relu')(maxpool2d_1)
    #드롭아웃
    dropout_2 = tf.keras.layers.Dropout(rate=0.4)(conv2d_2) #(드롭단위 비율, 호출인수)
    maxpool2d_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(dropout_2) #dropout_2 size(2, 2)로 축소
    
    
    
    flat_1 = tf.keras.layers.Flatten()(maxpool2d_2) #입력 평평하게, 배치크기 동일 (추가예정)
    #소프트맥스
    softmax = tf.keras.layers.Dense(units=num_classes, kernel_initializer='glorot_normal', activation='softmax')(flat_1)
    #출력데이터에 소프트맥스 입력
    output_data = softmax

    
    model = tf.keras.models.Model(inputs=[input_data], outputs=[output_data])
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),
                  loss=tf.keras.losses.categorical_crossentropy,
                  metrics=['accuracy'])
    # 입력, 출력 / adam, 손실함수=categorical_crossentropy, 출력 레이블 = 정확도
    return model

---------------------------------------------------------------------------------------------
if __name__ == '__main__':
    model = build_model(x_train.shape)

    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')
    model.fit(x=x_train, y=y_train, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tensorboard_callback]) 

    train_loss, train_accuracy = model.evaluate(x=x_train, y=y_train)
    print('train data loss:{:2.4f}'.format(train_loss))
    print('train accuracy:{:2.4f}'.format(train_accuracy))

    test_loss, test_accuracy = model.evaluate(x=x_test, y=y_test)
    print('test data loss:{:2.4f}'.format(test_loss))
    print('test accuracy:{:2.4f}'.format(test_accuracy))
    
    model.summary()
    with open('model_report.txt','w') as fh:
        model.summary(print_fn=lambda x: fh.write(x + '\n'))

    model.save('model.h5')
